<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>1.1 é¢„è®­ç»ƒ | Hexo</title>
    
<link rel="stylesheet" href="/css/style.css">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          TeX: {
            extensions: ["amsmath.js", "cancel.js"],
          }
        });
    </script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"/>
<meta name="generator" content="Hexo 7.3.0"></head>
<body>
    <div class="container">
        <header class="post-navbar">
    <div class="nav-left">
        <div class="nav-item search-trigger">
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"><path fill="currentColor" d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0 0 20 11c0-4.97-4.03-9-9-9s-9 4.03-9 9 4.03 9 9 9c2.49 0 4.74-1.01 6.32-2.67l3.68 3.68a1 1 0 0 0 1.42 0a1 1 0 0 0 0-1.42ZM4 11a7 7 0 1 1 14 0a7 7 0 0 1-14 0Z"/></svg>
            <span style="font-size: small;">æœç´¢...</span>
            <span class="search-shortcut" style="font-size: small;">Ctrl K</span>
        </div>
    </div>
    <div style="width: 10px;"></div>
    <div class="nav-right">
        <div class="nav-item theme-switcher">
            <svg class="sun" xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 12a4 4 0 1 0 8 0a4 4 0 1 0-8 0m-5 0h1m8-7V4m-5.6 1.4L4.8 6.8M16 17.2l1.4 1.4M20 12h1m-6-5.2l1.4-1.4M12 21v-1"/></svg>
            <svg class="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3a6 6 0 0 0 9 9a9 9 0 1 1-9-9Z"/></svg>
        </div>
    </div>
</header>

<div id="search-modal" class="modal-overlay" style="display: none;">
    <div class="modal-content">
        <input type="text" id="search-input" placeholder="è¾“å…¥å…³é”®å­—æœç´¢...">
        <div id="search-results"></div>
    </div>
</div>
<div class="post-layout">
  <aside class="post-sidebar">
    
    
      
      <nav>
          <div class="sidebar-top">
              <a href="/" class="back-to-home-link" style="display: flex; align-items: center">
                  <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 20"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m15 18l-6-6l6-6"/></svg>
                  <span>è¿”å›é¦–é¡µ</span>
              </a>
              <h3>å¤§è¯­è¨€æ¨¡å‹</h3>
          </div>
          <ul>
              
                  <li class="sidebar-group">
                      <details open>
                          <summary>
                              <svg class="sidebar-arrow" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="m15.5 12.001l-5.75 5.75c-.15.15-.325.225-.525.225s-.375-.075-.525-.225c-.3-.3-.3-.775 0-1.075l5.225-5.25l-5.225-5.25c-.3-.3-.3-.775 0-1.075s.775-.3 1.075 0l5.75 5.75c.15.15.225.325.225.525s-.075.375-.225.525Z"/></svg>
                              <span class="sidebar-summary-text">1 å¼ºåŒ–å­¦ä¹ </span>
                          </summary>
                          <div class="details-content">
                              <ul>
                                  
                                      <li class="sidebar-item ">
                                          <a href="/2025/09/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/1.1-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/">1.1 Q-Learning</a>
                                      </li>
                                  
                              </ul>
                          </div>
                      </details>
                  </li>
              
                  <li class="sidebar-group">
                      <details open>
                          <summary>
                              <svg class="sidebar-arrow" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="m15.5 12.001l-5.75 5.75c-.15.15-.325.225-.525.225s-.375-.075-.525-.225c-.3-.3-.3-.775 0-1.075l5.225-5.25l-5.225-5.25c-.3-.3-.3-.775 0-1.075s.775-.3 1.075 0l5.75 5.75c.15.15.225.325.225.525s-.075.375-.225.525Z"/></svg>
                              <span class="sidebar-summary-text">1 æ„å»ºä¸€ä¸ªå¤§æ¨¡å‹</span>
                          </summary>
                          <div class="details-content">
                              <ul>
                                  
                                      <li class="sidebar-item active">
                                          <a href="/2025/08/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/2.1-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83/">1.1 é¢„è®­ç»ƒ</a>
                                      </li>
                                  
                              </ul>
                          </div>
                      </details>
                  </li>
              
                  <li class="sidebar-group">
                      <details open>
                          <summary>
                              <svg class="sidebar-arrow" xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="m15.5 12.001l-5.75 5.75c-.15.15-.325.225-.525.225s-.375-.075-.525-.225c-.3-.3-.3-.775 0-1.075l5.225-5.25l-5.225-5.25c-.3-.3-.3-.775 0-1.075s.775-.3 1.075 0l5.75 5.75c.15.15.225.325.225.525s-.075.375-.225.525Z"/></svg>
                              <span class="sidebar-summary-text">3 åº”ç”¨å¼€å‘</span>
                          </summary>
                          <div class="details-content">
                              <ul>
                                  
                                      <li class="sidebar-item ">
                                          <a href="/2025/09/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/3.1-LangChain/">3.1 LangChainç®€ä»‹</a>
                                      </li>
                                  
                                      <li class="sidebar-item ">
                                          <a href="/2025/09/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/3.2-RAG/">3.2 RAG</a>
                                      </li>
                                  
                                      <li class="sidebar-item ">
                                          <a href="/2025/08/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/3.3-Agent/">3.3 Agent</a>
                                      </li>
                                  
                              </ul>
                          </div>
                      </details>
                  </li>
              
          </ul>
      </nav>
    
  </aside>

  <article class="post-content">
    

    <h1>1.1 é¢„è®­ç»ƒ</h1>
    <div class="post-meta">
      
        <time class="post-date-tag" datetime="2025-08-18T16:00:00.000Z">
            å‘å¸ƒäº: 2025-08-19
        </time>
      
    </div>
    <div class="post-body">
        <p>é¢„è®­ç»ƒï¼šä»é›¶å¼€å§‹çš„å¤§æ¨¡å‹è®­ç»ƒï¼Œæ‰€æœ‰çš„å‚æ•°éƒ½æ˜¯éšæœºåˆå§‹åŒ–ã€‚è¿™éœ€è¦å¤§é‡çš„è¯­æ–™ã€æ˜¾å¡ä»¥åŠæ—¶é—´æ‰èƒ½è®­ç»ƒå‡ºä¸€ä¸ªä¸é”™çš„æ¨¡å‹ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éƒ½æ˜¯åœ¨å¼€æºçš„å·²ç»é¢„è®­ç»ƒå¥½çš„å¤§æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œé’ˆå¯¹æŸä¸€ç‰¹å®šçš„é¢†åŸŸæ¥åŠ å¼ºè®­ç»ƒï¼Œæå‡é€šç”¨æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†å’Œèƒ½åŠ›ã€‚</p>
<h1 id="1-å¤§æ¨¡å‹å·¥å…·transformers">1 å¤§æ¨¡å‹å·¥å…·transformers</h1>
<p>transformersæ˜¯huggingfaceğŸ¤—å¼€å‘çš„è‡ªç„¶è¯­è¨€å¤„ç†åº“ï¼Œå…¶ä¸­æœ‰å¾ˆå¤šå¤§æ¨¡å‹å¼€å‘æ‰€éœ€è¦çš„ç±»</p>
<h2 id="1-1-æ¨¡å‹å’Œåˆ†è¯å™¨çš„åŠ è½½ä¸ä¿å­˜">1.1 æ¨¡å‹å’Œåˆ†è¯å™¨çš„åŠ è½½ä¸ä¿å­˜</h2>
<ul>
<li>è‡ªåŠ©åˆ†è¯å™¨<code>AutoTokenizer</code>ï¼Œç”¨ç»Ÿä¸€çš„æ¥å£æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„åˆ†è¯å™¨ï¼Œæ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨åŒ¹é…å¯¹åº”çš„æ¨¡å‹åˆ†è¯å™¨ã€‚ä»¥bertä¸­æ–‡åˆ†è¯ä¸ºä¾‹
<ul>
<li><code>from_pretrained</code>ï¼šæ ¹æ®æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„åˆ›å»ºAutoTokenizerçš„å®ä¾‹ï¼ŒåŠ è½½å¯¹åº”çš„åˆ†è¯å™¨ã€‚æ ¹æ®æ¨¡å‹åç§°ä»ç½‘ä¸Šä¸‹è½½ï¼Œåœ¨Windowsæ“ä½œç³»ç»Ÿä¸‹<strong>é»˜è®¤</strong>ä¸‹è½½è·¯å¾„<code>~/.cache/huggingface/transformers/</code>ã€‚æƒ³è¦æ”¹å˜ä¸‹è½½è·¯å¾„ï¼Œä¿®æ”¹ç¯å¢ƒå˜é‡å³å¯ï¼š<code>os.environ[&quot;HF_HOME&quot;] = &quot;æœ¬åœ°è·¯å¾„&quot;</code>ã€‚è¯¥å‡½æ•°å’Œæ¨¡å‹åŠ è½½é‡Œé¢çš„åå­—æ˜¯ç›¸åŒçš„</li>
<li><code>tokenizer.tokenize(text)</code>ï¼šè·å¾—åˆ†è¯åçš„è¯å…ƒtokençš„åˆ—è¡¨</li>
<li><code>encode</code>ï¼šæ–‡æœ¬è½¬åŒ–ä¸ºæ•°å­—åºåˆ—ï¼›<code>decode</code>ï¼šæ•°å­—è½¬å›æ–‡æœ¬</li>
<li><code>save_pretrained('æœ¬åœ°è·¯å¾„')</code>ï¼šä¿å­˜åˆ°æœ¬åœ°</li>
<li>å®ä¾‹åŒ–å¯¹è±¡tokenizerå‚æ•°ï¼š
<ul>
<li><code>return_tensors=''</code>ï¼šptï¼Œpytorch tensorï¼›tfï¼Œtensorflowçš„å¼ é‡å¯¹è±¡ï¼›npï¼Œnumpy</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&quot;HF_ENDPOINT&quot;</span>] = <span class="hljs-string">&quot;https://hf-mirror.com&quot;</span>     <span class="hljs-comment"># ä½¿ç”¨é•œåƒ</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-chinese&quot;</span>)<br>text = <span class="hljs-string">&quot;ä»Šå¤©å¤©æ°”å¾ˆå·®ï¼&quot;</span><br>text_tokenized = tokenizer(text)<br><span class="hljs-built_in">print</span>(text_tokenized)<br><br><span class="hljs-comment"># ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ tokenizer.encode_plus(text, add_special_tokens=True) æ•ˆæœå’Œä¸Šé¢çš„ä¸€æ ·</span><br></code></pre></td></tr></table></figure>
<p>é¦–æ¬¡ä¼šä»å®˜ç½‘ä¸‹è½½åˆ†è¯å™¨çš„é…ç½®æ–‡ä»¶ã€‚å¯ä»¥çœ‹åˆ°bertä¸­æ–‡åˆ†è¯ä¹‹åçš„ç»“æœæ˜¯å­—å…¸ï¼Œ<code>input_ids</code>å­—æ®µå°±æ˜¯tokençš„ç¼–å·</p>
<p><img src="https://raw.githubusercontent.com/inferiorStudent/resource-CDN/main/llm/1.1-bert-tokenizer.png" alt=""></p>
<h1 id="3-é¢„è®­ç»ƒæµç¨‹">3 é¢„è®­ç»ƒæµç¨‹</h1>
<h2 id="3-1-æ¨¡å‹æ„å»º">3.1 æ¨¡å‹æ„å»º</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, LlamaConfig, LlamaForCausalLM<br><span class="hljs-keyword">import</span> torch<br><br>model_path = <span class="hljs-string">&#x27;Meta-Llama-3.1-8B-Instruct&#x27;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_path)<br>device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br><br>model = AutoModelForCausalLM.from_pretrained(<br>    model_path,<br>    low_cpu_mem_usage=<span class="hljs-literal">True</span><br>).to(device)<br>optimizer = torch.optim.AdamW(model.parameters())<br><br>text = <span class="hljs-string">&quot;æˆ‘åœ¨å…¬å¸ä¸Šç­ã€‚&quot;</span><br><span class="hljs-built_in">input</span> = tokenizer(text, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>)<br><span class="hljs-built_in">input</span> = &#123;k, x.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>.items()&#125;<br><span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;labels&#x27;</span>] = <span class="hljs-built_in">input</span>[<span class="hljs-string">&#x27;input_ids&#x27;</span>].clone()<br>output = model(**<span class="hljs-built_in">input</span>)<br><br><span class="hljs-comment"># ç”±äºä¼ å…¥äº†labelï¼Œå› æ­¤å‰å‘ä¼ æ’­æ—¶è‡ªåŠ¨è®¡ç®—loss</span><br>loss = output.loss<br>loss.backward()<br>optimizer.step()<br>optimizer.zero_grad()<br><br>model.save_pretrained(<span class="hljs-string">&#x27;output_dir&#x27;</span>)<br></code></pre></td></tr></table></figure>
<ul>
<li>ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œlosså‡½æ•°éƒ½æ˜¯æˆ‘ä»¬è‡ªå·±ç»™å®šçš„ï¼Œé‚£ä¹ˆè®­ç»ƒæ—¶å†…éƒ¨lossæ˜¯å¦‚ä½•è®¡ç®—çš„ï¼Ÿ</li>
</ul>
<p>ä»å¤´è®­ç»ƒä¸€ä¸ªå¤§æ¨¡å‹ï¼Œä½ ä¹Ÿå¯ä»¥è‡ªå®šä¹‰æ¨¡å‹çš„ç»“æ„</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> LlamaConfig, LlamaForCausalLM<br><br>config = LlamaConfig()<br>config.num_hidden_layers = <span class="hljs-number">6</span><br>config.hidden_size = <span class="hljs-number">1024</span><br>config.intermediate_size = <span class="hljs-number">4096</span><br>config.num_key_value_heads = <span class="hljs-number">8</span><br><span class="hljs-comment"># é…ç½®æ–‡ä»¶åˆå§‹åŒ–æ¨¡å‹ç»“æ„</span><br>model = LlamaForCausalLM(config)<br></code></pre></td></tr></table></figure>
<p>ä¸è¿‡å¤§æ¦‚ç‡cuda out of memoryï¼Œéœ€è¦<strong>é‡åŒ–åŠ è½½</strong>ã€<strong>LoRAè®­ç»ƒ</strong>ç­‰å‡å°‘æ˜¾å­˜å ç”¨çš„æŠ€æœ¯ã€‚å¦‚ä¸‹é‡‡ç”¨4æ¯”ç‰¹åŠ è½½</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BitsAndBytesConfig<br><span class="hljs-comment"># 4bit load</span><br>bnb_config = BitsAndBytesConfig(<br>    load_in_4bit=<span class="hljs-literal">True</span>,<br>    bnb_4bit_use_double_quant=<span class="hljs-literal">True</span>,<br>    bnb_4bit_quant_type=<span class="hljs-string">&quot;nf4&quot;</span>,<br>    bnb_4bit_compute_dtype=torch.bfloat16<br>)<br><br>model = AutoModelForCausalLM.from_pretrained(<br>    model_path,<br>    low_cpu_mem_usage=<span class="hljs-literal">True</span>,<br>    quantization_config=bnb_config<br>).to(device)<br></code></pre></td></tr></table></figure>
<p>åŠ ä¸Šç”ŸæˆLoRAæ¨¡å‹çš„é…ç½®ã€‚å½“ç„¶äº†ï¼ŒåŠ ä¸Šäº†LoRAå°±ç®—ä¸ä¸Šæ˜¯é¢„è®­ç»ƒäº†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> TaskType, LoraConfig, get_peft_model<br>peft_config = LoraConfig(<br>    r=<span class="hljs-number">8</span>,<br>    target_modules=[<br>        <span class="hljs-string">&quot;q_proj&quot;</span>,<br>        <span class="hljs-string">&quot;v_proj&quot;</span>,<br>        <span class="hljs-string">&quot;k_proj&quot;</span>,<br>        <span class="hljs-string">&quot;o_proj&quot;</span>,<br>        <span class="hljs-string">&quot;gate_proj&quot;</span>,<br>        <span class="hljs-string">&quot;down_proj&quot;</span>,<br>        <span class="hljs-string">&quot;up_proj&quot;</span><br>    ],<br>    task_type=TaskType.CASUAL_LM,<br>    lora_alpha=<span class="hljs-number">16</span>,<br>    lora_dropout=<span class="hljs-number">0.05</span><br>)<br>model = get_peft_model(model, peft_config)<br>model.print_trainable_parameters()<br>model.to(device)<br></code></pre></td></tr></table></figure>
<p>æ­¤å¤–ï¼Œå¦‚æœéœ€è¦ç”¨åˆ°å¤šGPUè®­ç»ƒï¼Œåªéœ€è¦åœ¨from_pretrainedä¸­æ·»åŠ ï¼š<code>device_map=&#123;&quot;&quot;: PartialState().process_index&#125;</code>ï¼Œå¯¼åŒ…ï¼š<code>from accelerate import PartialState</code>ã€‚</p>
<h2 id="3-2-æ•°æ®å¤„ç†">3.2 æ•°æ®å¤„ç†</h2>
<p>é…ç½®å¥½æ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡å¥½txtæ–‡æœ¬æ•°æ®ã€‚</p>
<ul>
<li>æ•°æ®æ¸…æ´—</li>
</ul>
<p>åœ¨æ–‡æœ¬ä¸­åŠ ä¸Šç‰¹æ®Šçš„tokenï¼Œå³tokenizerçš„<code>EOS</code>ï¼ˆend of sequenceï¼‰å’Œ<code>BOS</code>ã€‚æ¯”å¦‚LoRAä¸­ï¼šå¼€å§‹çš„åœ°æ–¹åŠ ä¸Š<code>&lt;|begin_of_text|&gt;</code>ï¼Œç»“æŸçš„åœ°æ–¹åŠ ä¸Š<code>&lt;|eot_id|&gt;</code>ã€‚ä¸åŒçš„æ¨¡å‹åŠ çš„ç‰¹æ®Šçš„tokenè‡ªç„¶ä¸åŒï¼Œéœ€è¦æŸ¥çœ‹é…ç½®æ–‡ä»¶</p>
<ul>
<li>åŠ è½½æ•°æ®</li>
</ul>
<p>é¦–å…ˆå°†ä¸€äº›é…ç½®æ”¾åœ¨training_argsé‡Œé¢</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass, field<br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomArguments</span>(transformers.TrainingArguments):<br>    lora_r: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">8</span>)<br>    num_proc: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">1</span>)			<span class="hljs-comment"># æ•°æ®å¤„ç†æ—¶çš„å¹¶è¡Œè¿›ç¨‹æ•°</span><br>    max_seq_length: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">32</span>)<br>    eval_strategy: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-string">&quot;steps&quot;</span>)	<span class="hljs-comment"># ä¸æƒ³éªŒè¯åˆ™è®¾ç½®ä¸º&quot;no&quot;</span><br>    eval_steps: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">100</span>)		<span class="hljs-comment"># å¤šå°‘æ­¥éªŒè¯ä¸€æ¬¡</span><br>    seed: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">0</span>)<br>    optim: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-string">&quot;adamw_torch&quot;</span>)<br>    num_train_epochs: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">1</span>)<br>    per_device_train_batch_size: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">1</span>)<br>    <br>    learning_rate: <span class="hljs-built_in">float</span> = field(default=<span class="hljs-number">5e-5</span>)<br>    weight_decay: <span class="hljs-built_in">float</span> = field(default=<span class="hljs-number">0</span>)<br>    warmup_steps: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">0</span>)<br>    lr_scheduler_type: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-string">&quot;linear&quot;</span>)<br>    gradient_checkpointing: <span class="hljs-built_in">bool</span> = field(default=<span class="hljs-literal">False</span>)<br>    bf16: <span class="hljs-built_in">bool</span> = field(default=<span class="hljs-literal">True</span>)<br>    gradient_accumulation_steps: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">1</span>)<br>    <br>    logging_steps: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">3</span>)<br>    save_strategy: <span class="hljs-built_in">str</span> = field(default=<span class="hljs-string">&quot;steps&quot;</span>)<br>    save_steps: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">3</span>)<br>    save_total_limit: <span class="hljs-built_in">int</span> = field(default=<span class="hljs-number">2</span>)<br><br>parser = transformers.HfArgumentParser(CustomArguments)<br>training_args = parser.parse_args_into_dataclasses()<br></code></pre></td></tr></table></figure>
<p>ç„¶åå†è¿›è¡Œæ•°æ®çš„å¤„ç†</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> chain<br><span class="hljs-keyword">import</span> transformers<br><br><span class="hljs-comment"># åŠ è½½dirä¸‹çš„æ‰€æœ‰txtæ–‡ä»¶</span><br>train_dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_dir=<span class="hljs-string">&quot;xxx&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br>eval_dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_dir=<span class="hljs-string">&quot;xxx&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)<br><br><span class="hljs-comment"># å®šä¹‰åˆ†è¯å‡½æ•°ï¼šå¯¹æ¯ä¸ªä¼ å…¥çš„æ–‡æœ¬æ ·æœ¬åˆ†è¯</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenization</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;text&quot;</span>])<br><br><span class="hljs-comment"># ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¿è¯åœ¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ åªæœ‰åœ¨ä¸»è¿›ç¨‹ä¸­è¿›è¡Œæ•°æ®å¤„ç† è€Œä¸æ˜¯æ¯ä¸ªè¿›ç¨‹ä¸­éƒ½å¤„ç†ï¼ˆé‡å¤ï¼‰</span><br><span class="hljs-keyword">with</span> training_args.main_process_first(desc=<span class="hljs-string">&quot;dataset map tokenization&quot;</span>):<br>    train_dataset = train_dataset.<span class="hljs-built_in">map</span>(tokenization, remove_colunms=[<span class="hljs-string">&quot;text&quot;</span>], num_proc=training_args.num_proc)<br>    eval_dataset = eval_dataset.<span class="hljs-built_in">map</span>(tokenization, remove_colunms=[<span class="hljs-string">&quot;text&quot;</span>], num_proc=training_args.num_proc)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):<br>    <span class="hljs-comment"># åˆå¹¶æ‰€æœ‰çš„æ–‡æœ¬</span><br>    concatenated_examples = &#123;k: <span class="hljs-built_in">list</span>(chain(*examples[k])) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()&#125;<br>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])<br>    <br>    total_length = (total_lenght // training_args.max_seq_length) * training_args.max_seq_length<br>    <br>    result = &#123;<br>        k: [t[i: i + training_args.max_seq_length] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, total_length, training_args.max_seq_length)] <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> concatenated_examples.items()<br>    &#125;<br>    <span class="hljs-comment"># å¢åŠ ä¸€ä¸ªlabelåˆ—</span><br>    <span class="hljs-comment">##### Llamaåœ¨è®¡ç®—lossæ—¶ä¼šå¤„ç†labelå’Œinputçš„å…³ç³»ï¼ˆé”™ä½ï¼‰</span><br>    result[<span class="hljs-string">&quot;labels&quot;</span>] = result[<span class="hljs-string">&quot;input_ids&quot;</span>].copy()<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">with</span> training_args.main_process_first(desc=<span class="hljs-string">&quot;dataset map tokenization&quot;</span>):<br>    train_dataset = train_dataset.<span class="hljs-built_in">map</span>(group_texts, num_proc=training_args.num_proc, batched=<span class="hljs-literal">True</span>)<br>    eval_dataset = eval_dataset.<span class="hljs-built_in">map</span>(group_texts, num_proc=training_args.num_proc, batched=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h2 id="3-3-è®­ç»ƒ">3.3 è®­ç»ƒ</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer<br><span class="hljs-keyword">import</span> warnings<br><br>warnings.filterwarnings(<span class="hljs-string">&quot;ignore&quot;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    trainer = Trainer(<br>        model=model,<br>        args=training_args,<br>        train_dataset=train_dataset,<br>        eval_dataset=eval_dataset<br>    )<br>    trainer.train()<br>    trainer.save_model(<span class="hljs-string">&quot;è·¯å¾„&quot;</span>)<br></code></pre></td></tr></table></figure>

    </div>
    <script>
    document.addEventListener('DOMContentLoaded', () => {
        const codeBlocks = document.querySelectorAll('figure.highlight');
    
        codeBlocks.forEach(block => {
            // 1. è·å–è¯­è¨€æ ‡ç­¾
            const lang = block.classList.contains('highlight') ? 
                         block.classList[1] : '';
    
            // 2. åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥åŒ…è£¹è¯­è¨€æ ‡ç­¾å’Œå¤åˆ¶æŒ‰é’®
            const toolbar = document.createElement('div');
            toolbar.className = 'highlight-toolbar';
    
            // 3. åˆ›å»ºè¯­è¨€æ ‡ç­¾
            if (lang) {
                const langLabel = document.createElement('span');
                langLabel.className = 'highlight-lang';
                langLabel.textContent = lang.toUpperCase();
                toolbar.appendChild(langLabel);
            }
    
            // 4. åˆ›å»ºå¤åˆ¶æŒ‰é’®
            const copyButton = document.createElement('button');
            copyButton.className = 'highlight-copy-btn';
            copyButton.textContent = 'å¤åˆ¶';
            
            copyButton.addEventListener('click', () => {
                const code = block.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.textContent).then(() => {
                        copyButton.textContent = 'å·²å¤åˆ¶!';
                        setTimeout(() => {
                            copyButton.textContent = 'å¤åˆ¶';
                        }, 2000);
                    }).catch(err => {
                        console.error('å¤åˆ¶å¤±è´¥: ', err);
                    });
                }
            });
            toolbar.appendChild(copyButton);
    
            // 5. å°†å·¥å…·æ æ’å…¥åˆ°ä»£ç å—ä¸­
            block.appendChild(toolbar);
        });
    });
</script>
  </article>
</div>

    </div>
    
<script src="/js/script.js"></script>

</body>
</html>